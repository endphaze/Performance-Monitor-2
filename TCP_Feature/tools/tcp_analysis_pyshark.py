import pyshark
import time
import os
import tools.utility as utility
import pandas as pd
from dataclasses import asdict
from collections import Counter, deque, defaultdict, namedtuple
from datetime import datetime

def tcp_analyze(pcap_file, target_ip, ports=None) -> utility.TCPOutputModel:
    
    print(f"Reading {pcap_file} with PyShark...")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    total_packets = 0
    relevant_packets = 0
    
    response_times = []
    request_sizes = []
    response_sizes = []
    data_points = []
    
    ports_count = Counter()
    endpoints_count = Counter()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Display Filter ‡πÉ‡∏´‡πâ TShark ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏•‡πà‡∏≤‡∏á
    display_filter = f"tcp.port == 8080 and ip"
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
    start_time = time.time()
    
    # ‡πÉ‡∏ä‡πâ FileCapture ‡∏≠‡πà‡∏≤‡∏ô .pcap ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÅ‡∏£‡∏°
    cap = pyshark.FileCapture(
        pcap_file, 
        display_filter=display_filter,
        keep_packets=False,
        use_json=True
    )

    print(f"{'No.':<8} | {'Source':<15} | {'Dest':<15} | {'RTT (ms)':<10}")
    print("-" * 60)

    try:
        for pkt in cap:
            total_packets += 1 # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: total ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô total ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô display filter
            
            
            try:                
                if not hasattr(pkt,"ip") and not hasattr(pkt,"tcp") :
                    continue
                ip_layer = pkt.ip
                tcp_layer = pkt.tcp
                # print(ip_layer.src, tcp_layer.srcport)
                
                
                # if hasattr(tcp_layer.analysis, "ack_rtt"):
                #     print(tcp_layer.analysis.ack_rtt)
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Port  (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á list ‡∏Ç‡∏≠‡∏á ports ‡∏°‡∏≤)
                # current_port = int(tcp_layer.srcport) if ip_layer.src == target_ip else int(tcp_layer.dstport)
                # if ports and current_port not in ports:
                #     continue
                
                
                
                
                relevant_packets += 1
                pkt_size = int(pkt.length)
                
                # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞ Request / Response
                if ip_layer.dst == target_ip and tcp_layer.dstport == "8080":
                    # Case: Request (‡∏™‡πà‡∏á‡∏´‡∏≤ Target)
                    request_sizes.append(pkt_size)
                    ports_count[int(tcp_layer.dstport)] += 1
                    endpoints_count[ip_layer.src] += 1
                    # print(ip_layer.src, tcp_layer.srcport, ip_layer.dst, tcp_layer.dstport)
                    
                elif ip_layer.src == target_ip and tcp_layer.srcport == "8080":
                    # Case: Response (‡∏™‡πà‡∏á‡∏à‡∏≤‡∏Å Target)
                    response_sizes.append(pkt_size)
                    
                    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ RTT ‡∏ó‡∏µ‡πà Wireshark ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ß‡πâ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                    if hasattr(tcp_layer.analysis, "ack_rtt"):
                        rtt_val = float(tcp_layer.analysis.ack_rtt)
                        response_times.append(rtt_val)
                        data_points.append((float(pkt.sniff_time.timestamp()), rtt_val))
                        
                        print(f"{pkt.number:<8} | {ip_layer.src:<15} | {ip_layer.dst:<15} | {rtt_val*1000:.2f} ms")

            except AttributeError:
                # ‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
                continue

    finally:
        cap.close()

    exec_time = time.time() - start_time

    return utility.TCPOutputModel(
        target_ip=target_ip,
        exec_time=exec_time,
        total_packets_count=total_packets, # ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô count ‡∏Ç‡∏≠‡∏á filtered packets
        relevant_packets_count=relevant_packets,
        top_endpoints=endpoints_count.most_common(5),
        top_ports=ports_count.most_common(5),
        response_size=utility.get_MinMaxAvg(response_sizes),
        request_size=utility.get_MinMaxAvg(request_sizes),
        response_time=utility.get_MinMaxAvg(response_times),
        graph_response_time=data_points
    )
    

def get_all_pending_reqs(pending_request: defaultdict):
    all = 0
    for v in pending_request.values():
        all += len(v)
    return all

def tcp_analyze_http1(pcap_file, target_ip, output_folder = "", ports=[], limit=None) -> utility.TCPOutputModel:
    
    if output_folder == "":
        output_folder = "result"
    
    port_str = "_".join(map(str, ports)) if ports else "all"
    output_file = f"{output_folder}/{target_ip}_{port_str}_analysis.csv"
    
    # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏¥‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
    if os.path.exists(output_file):
        os.remove(output_file)
    
    chunk = []
    chunk_size = 10000
    start_time = time.time()
    resp_times = []
    # port_filter = " ".join(map(str, ports))
    # display_filter = f"ip.addr == {target_ip} and tcp.port in {{{port_filter}}}"
    
    
    if ports:
        port_filter = " or ".join([f"tcp.port == {p}" for p in ports])
        display_filter = f"ip.addr == {target_ip} and ({port_filter}) and tcp and tcp.payload > 0"
    else:
        display_filter = f"ip.addr == {target_ip} and tcp.payload > 0 and tcp"
    
    cap = pyshark.FileCapture(
        pcap_file,
        display_filter="tcp",
        keep_packets=False,
        use_json=False
    )
    
    tshark_filterd_time = time.time() - start_time()
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ï‡πà‡∏≤‡∏á‡πÜ
    relevant_packets = 0
    total_packets = 0
    endpoints_count = Counter()
    ports_count = Counter()
    response_sizes = []
    request_sizes = []
    response_times = []
    active_streams = set()
    
    
    graph_data_lst = []
    
    cap = pyshark.FileCapture(
        pcap_file,
        display_filter=display_filter,
        keep_packets=False,
        use_json=True
    )

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á Request ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Stream ID
    pending_requests = defaultdict(dict)
    
    print(f"{'Stream':<8} | {"Req Index":<8} | {"Resp Index":<8} | {'Response Time (ms)':<12}")
    print("-" * 50)
    
    try:
        for pkt in cap:            
            if limit and total_packets > limit:
                break
            try:
                
                ip_layer = pkt.ip
                tcp_layer = pkt.tcp
                total_packets +=1
                stream_id = tcp_layer.stream
                curr_time = float(pkt.sniff_timestamp)
                payload_len = int(tcp_layer.len)
                
                
                # --- 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô/‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ---
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ stream ‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á active
                active_streams.add(stream_id)

                # --- 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ (FIN ‡∏´‡∏£‡∏∑‡∏≠ RST) ---
                # ‡πÄ‡∏ä‡πá‡∏Ñ Flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                flags = int(tcp_layer.flags, 16)
                FIN = 0x01
                RST = 0x04
                
                if flags & FIN or flags & RST:
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å set
                    if stream_id in active_streams:
                        active_streams.remove(stream_id)
                
                
                metrics = utility.PacketMetrics(
                    time=curr_time,
                    response_time=0,
                    conn_count=len(active_streams),
                    pending_req=get_all_pending_reqs(pending_requests),
                    stream_id=stream_id,
                    role=""
                )
                
                
                
                
                if len(chunk) >= chunk_size:
                    df_chunk = pd.DataFrame(chunk)
                    # append ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå, header ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå
                    df_chunk.to_csv(output_file, mode='a', index=False, 
                                header=not os.path.exists(output_file))
                    chunk = [] # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÅ‡∏£‡∏°
                    print(f"Saved chunk: {total_packets} packets processed...")
                    
                    
                # ‡πÅ‡∏¢‡∏Å‡∏ù‡∏±‡πà‡∏á Client ‡πÅ‡∏•‡∏∞ Server
                if ip_layer.src == ip_layer.dst:
                    # ‡∏Å‡∏£‡∏ì‡∏µ Loopback: ‡πÉ‡∏ä‡πâ Port ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏´‡∏•‡∏±‡∏Å
                    is_from_client = (int(tcp_layer.dstport) in ports)
                else:
                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ: ‡πÉ‡∏ä‡πâ IP ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô
                    is_from_client = (ip_layer.dst == target_ip)
                    
                # 1. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Data ‡∏à‡∏≤‡∏Å Client -> Server ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ Request
                if is_from_client:
                    pending_requests[stream_id][tcp_layer.nxtseq] = {"time": curr_time,
                        "idx": pkt.number,
                        "seq": tcp_layer.seq}
                    ports_count[tcp_layer.dstport] += 1
                    endpoints_count[ip_layer.src] += 1
                    metrics.role = "request"
                    #print("request:stream_id", stream_id, payload_len, f"index: {pkt.number}")
                
                
                # 2. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Data ‡∏à‡∏≤‡∏Å Server -> Client ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ Response
                elif not is_from_client:
                    if stream_id in pending_requests and tcp_layer.ack in pending_requests[stream_id]:
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
                        relevant_packets += 1
                        req = pending_requests[stream_id].pop(tcp_layer.ack)
                        app_res_time = (curr_time - req["time"]) * 1000
                        resp_times.append(round(app_res_time,2))
                        
                        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ß‡∏Å (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ Out-of-order)
                        if app_res_time > 0:
                            #print("\nresponse:stream_id", stream_id, f"request idx {req["idx"]} responsed by idx {pkt.number}", "response time =", round(app_res_time,2))
                            #print(f"req_seq = {req["seq"]}", f"resp_seq = {pkt.tcp.seq}, resp_ack {pkt.tcp.ack}")
                            metrics.response_time = round(app_res_time, 3)
                            metrics.role = "response"
                            print(f"{stream_id:<8} | {req["idx"]:<9} | {pkt.number:<10} | {app_res_time:>10.3f} ms")
                            
                

                
                chunk.append(asdict(metrics))
            except AttributeError as e:
                print(e)
                continue
        
        print("matched pairs", relevant_packets)
        print(utility.get_MinMaxAvg(resp_times))
        print("total", total_packets)
        print("\ntcp stream connection counts", len(pending_requests))
        cant_find_response = 0
        for reqs in pending_requests.values():
            cant_find_response += len(reqs)
            
        print(f"{cant_find_response} requests cant find response.")
        
        
    finally:
        cap.close()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô chunk ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        if chunk:
            pd.DataFrame(chunk).to_csv(output_file, mode='a', index=False, 
                                     header=not os.path.exists(output_file))
            
        
        exec_time = time.time() - start_time
        
        return utility.TCPOutputModel(
        target_ip=target_ip,
        tshark_filterd_time=tshark_filterd_time,
        exec_time=exec_time,
        total_packets_count=total_packets, # ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô count ‡∏Ç‡∏≠‡∏á filtered packets
        relevant_packets_count=relevant_packets,
        top_endpoints=endpoints_count.most_common(5),
        top_ports=ports_count.most_common(5),
        response_size=utility.get_MinMaxAvg(response_sizes),
        request_size=utility.get_MinMaxAvg(request_sizes),
        response_time=utility.get_MinMaxAvg(response_times),
        csv_file=output_file
    )


# def get_https_app_response_time2(pcap_file, target_ip, ports=[], limit=None) -> utility.TCPOutputModel:
#     start_time = time.time()
    
#     # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
#     total_packets = 0
#     relevant_packets = 0
#     endpoints_count = Counter()
#     ports_count = Counter()
    
#     # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Model
#     request_sizes = []
#     response_sizes = []
#     response_times = []
#     data_points = []

#     # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Matching (FIFO)
#     # { stream_id: deque([ {'expect_ack': 123, 'time': 1.1, 'idx': 10}, ... ]) }
#     pending_requests = {}
    
#     # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡∏ô‡∏≤‡∏î Response (Multi-packet)
#     # { (stream_id, ack): total_payload_size }
#     active_responses_size = {}

#     # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ‡∏ñ‡πâ‡∏≤ ports ‡∏ß‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏Ñ‡πà target_ip ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
#     if ports:
#         port_filter = " or ".join([f"tcp.port == {p}" for p in ports])
#         display_filter = f"ip.addr == {target_ip} and ({port_filter})"
#     else:
#         display_filter = f"ip.addr == {target_ip}"
    
#     cap = pyshark.FileCapture(
#         pcap_file,
#         display_filter=display_filter,
#         keep_packets=False,
#         use_json=True
#     )

#     print(f"{'No.':<8} | {'Stream':<8} | {'Event':<15} | {'Latency':<10}")
#     print("-" * 50)

#     try:
#         for pkt in cap:
#             if limit and total_packets >= limit:
#                 break
#             total_packets += 1
            
#             try:
#                 tcp = pkt.tcp
#                 ip = pkt.ip
#                 stream_id = tcp.stream
#                 curr_time = float(pkt.sniff_timestamp)
#                 payload_len = int(tcp.len)
                
#                 # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Endpoints/Ports
#                 endpoints_count[ip.src if ip.dst == target_ip else ip.dst] += 1
#                 ports_count[tcp.srcport if ip.dst == target_ip else tcp.dstport] += 1

#                 # ‡πÅ‡∏¢‡∏Å‡∏ù‡∏±‡πà‡∏á Client (‡∏™‡πà‡∏á‡∏´‡∏≤ Target) ‡πÅ‡∏•‡∏∞ Server (Target ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤)
#                 if ip.src == ip.dst:
#                     # ‡∏Å‡∏£‡∏ì‡∏µ Loopback: ‡πÉ‡∏ä‡πâ Port ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏´‡∏•‡∏±‡∏Å
#                     is_from_client = (int(tcp.dstport) in ports)
#                 else:
#                     # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ: ‡πÉ‡∏ä‡πâ IP ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô
#                     is_from_client = (ip.dst == target_ip)

#                 # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Request (Client -> Server)
#                 if is_from_client and payload_len > 0:
                    
#                     request_sizes.append(payload_len)
                    
#                     # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Ack ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏à‡∏≤‡∏Å Server
#                     expect_ack = int(tcp.seq) + payload_len
                    
#                     if stream_id not in pending_requests:
#                         pending_requests[stream_id] = deque()
                    
#                     pending_requests[stream_id].append({
#                         "expect_ack": expect_ack,
#                         "time": curr_time,
#                         "idx": pkt.number
#                     })
#                     print(f"{pkt.number:<8} | {stream_id:<8} | REQUEST | {payload_len}")

#                 # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Response (Server -> Client)
#                 elif not is_from_client and payload_len > 0:
                    
#                     # print(ip.src, tcp.srcport, ip.dst, tcp.dstport)
#                     server_ack = int(tcp.ack)
                    
#                     # ‡∏Å‡∏£‡∏ì‡∏µ A: ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á Response (TTFB)
#                     if stream_id in pending_requests and pending_requests[stream_id]:
#                         first_req = pending_requests[stream_id][0]
                        
#                         if server_ack == first_req["expect_ack"]:
#                             req = pending_requests[stream_id].popleft()
#                             latency = (curr_time - req["time"]) * 1000
                            
#                             if latency > 0:
#                                 response_times.append(latency)
#                                 data_points.append((curr_time, latency))
#                                 # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡∏ô‡∏≤‡∏î Response ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ack ‡∏ô‡∏µ‡πâ
#                                 active_responses_size[(stream_id, server_ack)] = payload_len
                                
#                                 print(f"{pkt.number:<8} | {stream_id:<8} | RESPONSE | {latency:.2f} ms (Match Req {req['idx']})")
                    
#                     # ‡∏Å‡∏£‡∏ì‡∏µ B: ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Response ‡πÄ‡∏î‡∏¥‡∏° (Multi-packet)
#                     elif (stream_id, server_ack) in active_responses_size:
#                         active_responses_size[(stream_id, server_ack)] += payload_len

#             except AttributeError:
#                 continue

#         # ‡∏ô‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î Response ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏™‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà‡∏•‡∏á list
#         response_sizes = list(active_responses_size.values())
#         print("matched packet", relevant_packets)
#     finally:
#         cap.close()
#         exec_time = time.time() - start_time
        
#         return utility.TCPOutputModel(
#             target_ip=target_ip,
#             exec_time=exec_time,
#             total_packets_count=total_packets,
#             relevant_packets_count=relevant_packets,
#             top_endpoints=endpoints_count.most_common(5),
#             top_ports=ports_count.most_common(5),
#             response_size=utility.get_MinMaxAvg(response_sizes),
#             request_size=utility.get_MinMaxAvg(request_sizes),
#             response_time=utility.get_MinMaxAvg(response_times),
#             graph_response_time=data_points
#         )



# def get_https_app_response_time3(pcap_file, target_ip, ports=[443], limit=None) -> utility.TCPOutputModel:
#     start_time = time.time()
    
#     response_times = []
#     request_sizes = []
#     response_sizes = [] 
#     data_points = []
    
#     endpoints_count = Counter()
#     ports_count = Counter()
#     total_packets = 0
#     relevant_packets = 0

#     pending_requests = {} 
#     active_responses = {}

#     port_filter = " or ".join([f"tcp.port == {p}" for p in ports])
#     display_filter = f"ip.addr == {target_ip} and ({port_filter})"
    
#     print(f"\n{'='*95}")
#     print(f"üì° Analyzing: {pcap_file} | Target IP: {target_ip} | Limit: {limit if limit else 'Full File'}")
#     print(f"{'='*95}\n")
#     print(f"{'No.':<8} | {'Stream':<8} | {'Event':<15} | {'Size (B)':<10} | {'Info/Latency'}")
#     print(f"{'-'*95}")

#     cap = pyshark.FileCapture(
#         pcap_file,
#         display_filter=display_filter,
#         keep_packets=False,
#         use_json=True
#     )

#     try:
#         for pkt in cap:
#             # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Limit
#             if limit and total_packets >= limit:
#                 print(f"\n[!] Reached limit of {limit} packets. Stopping analysis...")
#                 break
                
#             total_packets += 1
#             try:
#                 tcp_layer = pkt.tcp
#                 stream_id = tcp_layer.stream
#                 curr_time = float(pkt.sniff_timestamp)
#                 payload_len = int(tcp_layer.len)
                
#                 endpoints_count[pkt.ip.src if pkt.ip.dst == target_ip else pkt.ip.dst] += 1
#                 ports_count[tcp_layer.srcport if pkt.ip.dst == target_ip else tcp_layer.dstport] += 1

#                 is_from_client = (pkt.ip.dst == target_ip)

#                 # --- [1] ‡∏ù‡∏±‡πà‡∏á REQUEST (Client -> Server) ---
#                 if is_from_client and payload_len > 0:
#                     relevant_packets += 1
#                     expect_ack = int(tcp_layer.seq) + payload_len
                    
#                     if stream_id not in pending_requests:
#                         pending_requests[stream_id] = deque()
                    
#                     pending_requests[stream_id].append({
#                         "expect_ack": expect_ack,
#                         "time": curr_time,
#                         "idx": pkt.number
#                     })
#                     request_sizes.append(payload_len)
                    
#                     print(f"{pkt.number:<8} | {stream_id:<8} | REQUEST         | {payload_len:<10} | ExpAck: {expect_ack}")

#                 # --- [2] ‡∏ù‡∏±‡πà‡∏á RESPONSE (Server -> Client) ---
#                 elif not is_from_client and payload_len > 0:
#                     relevant_packets += 1
#                     server_ack = int(tcp_layer.ack)
#                     res_key = (stream_id, server_ack)

#                     # ‡∏Å‡∏£‡∏ì‡∏µ A: ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Multi-packet Response)
#                     if res_key in active_responses:
#                         active_responses[res_key]['total_size'] += payload_len
#                         # ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏ö‡∏≤‡πÜ ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
#                         print(f"{pkt.number:<8} | {stream_id:<8} | RESP_CONT       | {payload_len:<10} | (Accumulating for Req#{active_responses[res_key]['req_idx']})")
                    
#                     # ‡∏Å‡∏£‡∏ì‡∏µ B: ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á Response ‡πÉ‡∏´‡∏°‡πà (TTFB)
#                     elif stream_id in pending_requests and pending_requests[stream_id]:
#                         # ‡∏´‡∏≤ Request ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ExpectAck ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Ack ‡∏Ç‡∏≠‡∏á Server
#                         # ‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡πÉ‡∏ô Queue (FIFO)
#                         first_req = pending_requests[stream_id][0]
                        
#                         if server_ack == first_req["expect_ack"]:
#                             req = pending_requests[stream_id].popleft()
#                             app_res_time = (curr_time - req["time"]) * 1000 
                            
#                             if app_res_time > 0:
#                                 response_times.append(app_res_time)
#                                 data_points.append((curr_time, app_res_time))
                                
#                                 active_responses[res_key] = {
#                                     'total_size': payload_len,
#                                     'req_idx': req['idx']
#                                 }
                                
#                                 print(f"{pkt.number:<8} | {stream_id:<8} | RESPONSE_START  | {payload_len:<10} | Match Req#{req['idx']} -> {app_res_time:.2f} ms")

#             except AttributeError:
#                 continue

#         # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
#         print(f"\n{'-'*95}")
#         print(f"üìä Summary of Analysis:")
#         for res in active_responses.values():
#             response_sizes.append(res['total_size'])
        
#         pending_total = sum(len(q) for q in pending_requests.values())
#         print(f"Total Filtered Packets: {total_packets}")
#         print(f"Relevant Data Packets: {relevant_packets}")
#         print(f"Pending Requests (No response found): {pending_total}")

#     finally:
#         cap.close()
        
#     exec_time = time.time() - start_time
#     print(f"Execution Time: {exec_time:.2f}s")
#     print(f"{'='*95}\n")
    
#     return utility.TCPOutputModel(
#         target_ip=target_ip,
#         tshark
#         exec_time=exec_time,
#         total_packets_count=total_packets,
#         relevant_packets_count=relevant_packets,
#         top_endpoints=endpoints_count.most_common(5),
#         top_ports=ports_count.most_common(5),
#         response_size=utility.get_MinMaxAvg(response_sizes),
#         request_size=utility.get_MinMaxAvg(request_sizes),
#         response_time=utility.get_MinMaxAvg(response_times),
#         graph_response_time=data_points
#     ) 
    
    
# def tcp_analyze_http1_optimized(pcap_file, target_ip, ports=[], limit=None) -> utility.TCPOutputModel:
#     start_time = time.time()
    
    
#     port_str = "_".join(map(str, ports)) if ports else "all"
#     output_file = f"result/{target_ip}_{port_str}_analysis.csv"
    
#     # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏¥‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
#     if os.path.exists(output_file):
#         os.remove(output_file)
    
#     chunk = []
#     chunk_size = 10000
        
#     # 1. ‡∏õ‡∏£‡∏±‡∏ö Display Filter ‡πÉ‡∏´‡πâ‡∏î‡∏±‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ Data (tcp.len > 0)
#     # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡πá‡∏ï‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤ Loop ‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50% (‡∏Ç‡πâ‡∏≤‡∏°‡∏û‡∏ß‡∏Å ACK ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ)
#     port_filter = ""
#     if ports:
#         port_list = " ".join(map(str, ports))
#         port_filter = f" and tcp.port in {{{port_list}}}"

#     # ‡πÄ‡∏û‡∏¥‡πà‡∏° 'tcp.len > 0' ‡πÉ‡∏ô filter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
#     display_filter = f"ip.addr == {target_ip} and tcp.len > 0{port_filter}"
    
#     # 2. ‡∏õ‡∏£‡∏±‡∏ö Parameter ‡∏Ç‡∏≠‡∏á TShark ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
#     # -n: ‡∏õ‡∏¥‡∏î Name Resolution
#     # -o tcp.desegment_tcp_streams:FALSE: ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ RAM
#     custom_params = ['-n', '-o', 'tcp.desegment_tcp_streams:FALSE']

#     cap = pyshark.FileCapture(
#         pcap_file,
#         display_filter=display_filter,
#         keep_packets=False,
#         use_json=True,
#         custom_parameters=custom_params
#     )

#     relevant_packets = 0
#     total_packets = 0
#     resp_times = []
#     data_points = []
    
#     # ‡πÉ‡∏ä‡πâ dict ‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏ó‡∏ô defaultdict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏ô loop ‡πÉ‡∏´‡∏ç‡πà
#     pending_requests = {} 

#     print(f"Analyzing {pcap_file} (Optimized)...")

#     try:
#         for pkt in cap:
#             total_packets += 1
#             if limit and total_packets > limit:
#                 break
                
#             try:
#                 tcp = pkt.tcp
#                 ip = pkt.ip
#                 stream_id = tcp.stream
#                 curr_time = float(pkt.sniff_timestamp)
                
#                 # ‡πÅ‡∏¢‡∏Å‡∏ù‡∏±‡πà‡∏á Client/Server (‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏ä‡πá‡∏Ñ IP ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á)
#                 is_from_client = (ip.dst == target_ip)
                
#                 # 1. Request (Client -> Server)
#                 if is_from_client:
#                     if stream_id not in pending_requests:
#                         pending_requests[stream_id] = {}
                    
#                     # ‡∏à‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà nxtseq ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ ACK ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
#                     pending_requests[stream_id][tcp.nxtseq] = curr_time
                
#                 # 2. Response (Server -> Client)
#                 else:
#                     # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ ACK ‡∏ô‡∏µ‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Request ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡πÉ‡∏ô Stream ‡∏ô‡∏µ‡πâ
#                     if stream_id in pending_requests:
#                         req_time = pending_requests[stream_id].pop(tcp.ack, None)
                        
#                         if req_time:
#                             app_res_time = (curr_time - req_time) * 1000
                            
#                             if app_res_time > 0:
#                                 relevant_packets += 1
#                                 resp_times.append(round(app_res_time, 2))
#                                 data_points.append((curr_time, app_res_time))

#             except AttributeError:
#                 continue

#     finally:
#         cap.close()

#     exec_time = time.time() - start_time
    
#     # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö (‡πÉ‡∏ä‡πâ utility ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ)
#     return utility.TCPOutputModel(
#         target_ip=target_ip,
#         exec_time=exec_time,
#         total_packets_count=total_packets,
#         relevant_packets_count=relevant_packets,
#         top_endpoints=[], # ‡πÄ‡∏û‡∏¥‡πà‡∏° Counter ‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
#         top_ports=[],
#         response_size=utility.get_MinMaxAvg([]),
#         request_size=utility.get_MinMaxAvg([]),
#         response_time=utility.get_MinMaxAvg(resp_times),
#         csv_file=output_file
#     )
    
    